{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5799070-f439-4a2f-804e-12f028731414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "018e8126-7901-4cf6-b050-612652238e9b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Using cached spacy-3.8.2.tar.gz (1.3 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  pip subprocess to install build dependencies did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [67 lines of output]\n",
      "  Ignoring numpy: markers 'python_version < \"3.9\"' don't match your environment\n",
      "  Collecting setuptools\n",
      "    Using cached setuptools-80.7.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Collecting cython<3.0,>=0.25\n",
      "    Using cached Cython-0.29.37-py2.py3-none-any.whl.metadata (3.1 kB)\n",
      "  Collecting cymem<2.1.0,>=2.0.2\n",
      "    Using cached cymem-2.0.11-cp313-cp313-win_amd64.whl.metadata (8.8 kB)\n",
      "  Collecting preshed<3.1.0,>=3.0.2\n",
      "    Using cached preshed-3.0.9.tar.gz (14 kB)\n",
      "    Installing build dependencies: started\n",
      "    Installing build dependencies: finished with status 'done'\n",
      "    Getting requirements to build wheel: started\n",
      "    Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing metadata (pyproject.toml): started\n",
      "    Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Collecting murmurhash<1.1.0,>=0.28.0\n",
      "    Using cached murmurhash-1.0.12-cp313-cp313-win_amd64.whl.metadata (2.2 kB)\n",
      "  Collecting thinc<8.4.0,>=8.3.0\n",
      "    Using cached thinc-8.3.6-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
      "  Collecting numpy<2.1.0,>=2.0.0\n",
      "    Using cached numpy-2.0.2.tar.gz (18.9 MB)\n",
      "    Installing build dependencies: started\n",
      "    Installing build dependencies: finished with status 'done'\n",
      "    Getting requirements to build wheel: started\n",
      "    Getting requirements to build wheel: finished with status 'done'\n",
      "    Installing backend dependencies: started\n",
      "    Installing backend dependencies: finished with status 'done'\n",
      "    Preparing metadata (pyproject.toml): started\n",
      "    Preparing metadata (pyproject.toml): finished with status 'error'\n",
      "    error: subprocess-exited-with-error\n",
      "  \n",
      "    Preparing metadata (pyproject.toml) did not run successfully.\n",
      "    exit code: 1\n",
      "  \n",
      "    [21 lines of output]\n",
      "    + C:\\Users\\LENOVO\\Desktop\\campus project AI\\career_recommendation_platform_ai\\venv\\Scripts\\python.exe C:\\Users\\LENOVO\\AppData\\Local\\Temp\\pip-install-fy46bkk0\\numpy_4099b73948f447fb9dc8fa384836858d\\vendored-meson\\meson\\meson.py setup C:\\Users\\LENOVO\\AppData\\Local\\Temp\\pip-install-fy46bkk0\\numpy_4099b73948f447fb9dc8fa384836858d C:\\Users\\LENOVO\\AppData\\Local\\Temp\\pip-install-fy46bkk0\\numpy_4099b73948f447fb9dc8fa384836858d\\.mesonpy-4ppnw8jb -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=C:\\Users\\LENOVO\\AppData\\Local\\Temp\\pip-install-fy46bkk0\\numpy_4099b73948f447fb9dc8fa384836858d\\.mesonpy-4ppnw8jb\\meson-python-native-file.ini\n",
      "    The Meson build system\n",
      "    Version: 1.4.99\n",
      "    Source dir: C:\\Users\\LENOVO\\AppData\\Local\\Temp\\pip-install-fy46bkk0\\numpy_4099b73948f447fb9dc8fa384836858d\n",
      "    Build dir: C:\\Users\\LENOVO\\AppData\\Local\\Temp\\pip-install-fy46bkk0\\numpy_4099b73948f447fb9dc8fa384836858d\\.mesonpy-4ppnw8jb\n",
      "    Build type: native build\n",
      "    Project name: NumPy\n",
      "    Project version: 2.0.2\n",
      "    WARNING: Failed to activate VS environment: Could not find C:\\Program Files (x86)\\Microsoft Visual Studio\\Installer\\vswhere.exe\n",
      "  \n",
      "    ..\\meson.build:1:0: ERROR: Unknown compiler(s): [['icl'], ['cl'], ['cc'], ['gcc'], ['clang'], ['clang-cl'], ['pgcc']]\n",
      "    The following exception(s) were encountered:\n",
      "    Running `icl \"\"` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "    Running `cl /?` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "    Running `cc --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "    Running `gcc --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "    Running `clang --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "    Running `clang-cl /?` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "    Running `pgcc --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "  \n",
      "    A full log can be found at C:\\Users\\LENOVO\\AppData\\Local\\Temp\\pip-install-fy46bkk0\\numpy_4099b73948f447fb9dc8fa384836858d\\.mesonpy-4ppnw8jb\\meson-logs\\meson-log.txt\n",
      "    [end of output]\n",
      "  \n",
      "    note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  error: metadata-generation-failed\n",
      "  \n",
      "  Encountered error while generating package metadata.\n",
      "  \n",
      "  See above for output.\n",
      "  \n",
      "  note: This is an issue with the package mentioned above, not pip.\n",
      "  hint: See above for details.\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "pip subprocess to install build dependencies did not run successfully.\n",
      "exit code: 1\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "C:\\Users\\LENOVO\\Desktop\\campus project AI\\career_recommendation_platform_ai\\venv\\Scripts\\python.exe: No module named spacy\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8285e844-cf35-4571-a0de-79070c542261",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.7\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac58feab-76ca-485f-b880-6c5672f6552d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting pdfminer.six\n",
      "  Using cached pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting spacy\n",
      "  Using cached spacy-3.8.2.tar.gz (1.3 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  pip subprocess to install build dependencies did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [67 lines of output]\n",
      "  Ignoring numpy: markers 'python_version < \"3.9\"' don't match your environment\n",
      "  Collecting setuptools\n",
      "    Using cached setuptools-80.7.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Collecting cython<3.0,>=0.25\n",
      "    Using cached Cython-0.29.37-py2.py3-none-any.whl.metadata (3.1 kB)\n",
      "  Collecting cymem<2.1.0,>=2.0.2\n",
      "    Using cached cymem-2.0.11-cp313-cp313-win_amd64.whl.metadata (8.8 kB)\n",
      "  Collecting preshed<3.1.0,>=3.0.2\n",
      "    Using cached preshed-3.0.9.tar.gz (14 kB)\n",
      "    Installing build dependencies: started\n",
      "    Installing build dependencies: finished with status 'done'\n",
      "    Getting requirements to build wheel: started\n",
      "    Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing metadata (pyproject.toml): started\n",
      "    Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Collecting murmurhash<1.1.0,>=0.28.0\n",
      "    Using cached murmurhash-1.0.12-cp313-cp313-win_amd64.whl.metadata (2.2 kB)\n",
      "  Collecting thinc<8.4.0,>=8.3.0\n",
      "    Using cached thinc-8.3.6-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
      "  Collecting numpy<2.1.0,>=2.0.0\n",
      "    Using cached numpy-2.0.2.tar.gz (18.9 MB)\n",
      "    Installing build dependencies: started\n",
      "    Installing build dependencies: finished with status 'done'\n",
      "    Getting requirements to build wheel: started\n",
      "    Getting requirements to build wheel: finished with status 'done'\n",
      "    Installing backend dependencies: started\n",
      "    Installing backend dependencies: finished with status 'done'\n",
      "    Preparing metadata (pyproject.toml): started\n",
      "    Preparing metadata (pyproject.toml): finished with status 'error'\n",
      "    error: subprocess-exited-with-error\n",
      "  \n",
      "    Preparing metadata (pyproject.toml) did not run successfully.\n",
      "    exit code: 1\n",
      "  \n",
      "    [21 lines of output]\n",
      "    + C:\\Users\\LENOVO\\Desktop\\campus project AI\\career_recommendation_platform_ai\\venv\\Scripts\\python.exe C:\\Users\\LENOVO\\AppData\\Local\\Temp\\pip-install-selc2kyh\\numpy_619c767a6d6e403f88e306e88b7d5e93\\vendored-meson\\meson\\meson.py setup C:\\Users\\LENOVO\\AppData\\Local\\Temp\\pip-install-selc2kyh\\numpy_619c767a6d6e403f88e306e88b7d5e93 C:\\Users\\LENOVO\\AppData\\Local\\Temp\\pip-install-selc2kyh\\numpy_619c767a6d6e403f88e306e88b7d5e93\\.mesonpy-de_bdbax -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=C:\\Users\\LENOVO\\AppData\\Local\\Temp\\pip-install-selc2kyh\\numpy_619c767a6d6e403f88e306e88b7d5e93\\.mesonpy-de_bdbax\\meson-python-native-file.ini\n",
      "    The Meson build system\n",
      "    Version: 1.4.99\n",
      "    Source dir: C:\\Users\\LENOVO\\AppData\\Local\\Temp\\pip-install-selc2kyh\\numpy_619c767a6d6e403f88e306e88b7d5e93\n",
      "    Build dir: C:\\Users\\LENOVO\\AppData\\Local\\Temp\\pip-install-selc2kyh\\numpy_619c767a6d6e403f88e306e88b7d5e93\\.mesonpy-de_bdbax\n",
      "    Build type: native build\n",
      "    Project name: NumPy\n",
      "    Project version: 2.0.2\n",
      "    WARNING: Failed to activate VS environment: Could not find C:\\Program Files (x86)\\Microsoft Visual Studio\\Installer\\vswhere.exe\n",
      "  \n",
      "    ..\\meson.build:1:0: ERROR: Unknown compiler(s): [['icl'], ['cl'], ['cc'], ['gcc'], ['clang'], ['clang-cl'], ['pgcc']]\n",
      "    The following exception(s) were encountered:\n",
      "    Running `icl \"\"` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "    Running `cl /?` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "    Running `cc --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "    Running `gcc --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "    Running `clang --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "    Running `clang-cl /?` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "    Running `pgcc --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "  \n",
      "    A full log can be found at C:\\Users\\LENOVO\\AppData\\Local\\Temp\\pip-install-selc2kyh\\numpy_619c767a6d6e403f88e306e88b7d5e93\\.mesonpy-de_bdbax\\meson-logs\\meson-log.txt\n",
      "    [end of output]\n",
      "  \n",
      "    note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  error: metadata-generation-failed\n",
      "  \n",
      "  Encountered error while generating package metadata.\n",
      "  \n",
      "  See above for output.\n",
      "  \n",
      "  note: This is an issue with the package mentioned above, not pip.\n",
      "  hint: See above for details.\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "pip subprocess to install build dependencies did not run successfully.\n",
      "exit code: 1\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "#download this tools for exptracting text from docs, and pdf\n",
    "!pip install python-docx pdfminer.six spacy nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7cb5c22b-c6c3-4f60-804a-db29613fb22f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyresparser\n",
      "  Downloading pyresparser-1.0.6-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyresparser) (25.3.0)\n",
      "Requirement already satisfied: blis>=0.2.4 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyresparser) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2019.6.16 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyresparser) (2024.8.30)\n",
      "Requirement already satisfied: chardet>=3.0.4 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyresparser) (4.0.0)\n",
      "Requirement already satisfied: cymem>=2.0.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyresparser) (2.0.11)\n",
      "Collecting docx2txt>=0.7 (from pyresparser)\n",
      "  Downloading docx2txt-0.9-py3-none-any.whl.metadata (529 bytes)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyresparser) (3.7)\n",
      "Requirement already satisfied: jsonschema>=3.0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyresparser) (4.23.0)\n",
      "Requirement already satisfied: nltk>=3.4.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyresparser) (3.9.1)\n",
      "Requirement already satisfied: numpy>=1.16.4 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyresparser) (2.2.5)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyresparser) (2.2.3)\n",
      "Requirement already satisfied: pdfminer.six>=20181108 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyresparser) (20250506)\n",
      "Requirement already satisfied: preshed>=2.0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyresparser) (3.0.9)\n",
      "Collecting pycryptodome>=3.8.2 (from pyresparser)\n",
      "  Downloading pycryptodome-3.22.0-cp37-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting pyrsistent>=0.15.2 (from pyresparser)\n",
      "  Downloading pyrsistent-0.20.0-cp312-cp312-win_amd64.whl.metadata (976 bytes)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyresparser) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2019.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyresparser) (2024.1)\n",
      "Requirement already satisfied: requests>=2.22.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyresparser) (2.32.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyresparser) (1.16.0)\n",
      "Requirement already satisfied: sortedcontainers>=2.1.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyresparser) (2.4.0)\n",
      "Requirement already satisfied: spacy>=2.1.4 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyresparser) (3.8.5)\n",
      "Requirement already satisfied: srsly>=0.0.7 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyresparser) (2.5.1)\n",
      "Requirement already satisfied: thinc>=7.0.4 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyresparser) (8.3.6)\n",
      "Requirement already satisfied: tqdm>=4.32.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyresparser) (4.66.5)\n",
      "Requirement already satisfied: urllib3>=1.25.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyresparser) (2.2.3)\n",
      "Requirement already satisfied: wasabi>=0.2.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyresparser) (1.1.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from jsonschema>=3.0.1->pyresparser) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from jsonschema>=3.0.1->pyresparser) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from jsonschema>=3.0.1->pyresparser) (0.10.6)\n",
      "Requirement already satisfied: click in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk>=3.4.3->pyresparser) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk>=3.4.3->pyresparser) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk>=3.4.3->pyresparser) (2024.9.11)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->pyresparser) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pdfminer.six>=20181108->pyresparser) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pdfminer.six>=20181108->pyresparser) (43.0.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from preshed>=2.0.1->pyresparser) (1.0.12)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from spacy>=2.1.4->pyresparser) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from spacy>=2.1.4->pyresparser) (1.0.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from spacy>=2.1.4->pyresparser) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from spacy>=2.1.4->pyresparser) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from spacy>=2.1.4->pyresparser) (0.15.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from spacy>=2.1.4->pyresparser) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from spacy>=2.1.4->pyresparser) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from spacy>=2.1.4->pyresparser) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from spacy>=2.1.4->pyresparser) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from spacy>=2.1.4->pyresparser) (3.5.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from thinc>=7.0.4->pyresparser) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tqdm>=4.32.2->pyresparser) (0.4.6)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six>=20181108->pyresparser) (1.17.1)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy>=2.1.4->pyresparser) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.1.4->pyresparser) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.1.4->pyresparser) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.1.4->pyresparser) (4.11.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy>=2.1.4->pyresparser) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy>=2.1.4->pyresparser) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy>=2.1.4->pyresparser) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy>=2.1.4->pyresparser) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from jinja2->spacy>=2.1.4->pyresparser) (2.1.3)\n",
      "Requirement already satisfied: pycparser in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six>=20181108->pyresparser) (2.21)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=2.1.4->pyresparser) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.1.4->pyresparser) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.1.4->pyresparser) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.1.4->pyresparser) (0.1.0)\n",
      "Downloading pyresparser-1.0.6-py3-none-any.whl (4.2 MB)\n",
      "   ---------------------------------------- 0.0/4.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.2 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 2.4/4.2 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.2/4.2 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.2/4.2 MB 8.5 MB/s eta 0:00:00\n",
      "Downloading docx2txt-0.9-py3-none-any.whl (4.0 kB)\n",
      "Downloading pycryptodome-3.22.0-cp37-abi3-win_amd64.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 1.3/1.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 7.0 MB/s eta 0:00:00\n",
      "Downloading pyrsistent-0.20.0-cp312-cp312-win_amd64.whl (63 kB)\n",
      "Installing collected packages: docx2txt, pyrsistent, pycryptodome, pyresparser\n",
      "Successfully installed docx2txt-0.9 pycryptodome-3.22.0 pyresparser-1.0.6 pyrsistent-0.20.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyresparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5923ee6e-807b-4ba5-af20-32485f29d25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize and load pretrained model from SpaCy which include tokenizer, tagger, parser,  NER, lemmatizer\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28be8142-3ba5-44ea-b89d-edf8dd167c40",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pytesseract) (24.1)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pytesseract) (10.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c29393b-a5f1-41ac-bfeb-9e40802f813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1: functional block for extracting the resume texts \n",
    "\n",
    "from pdfminer.high_level import extract_text as extract_text_from_pdf\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import docx\n",
    "from docx import Document\n",
    "import os\n",
    "\n",
    "def extract_text_from_image(file_path):\n",
    "    img = Image.open(file_path)\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    return text\n",
    "\n",
    "def extract_text(file_path):\n",
    "    extract = os.path.splitext(file_path)[-1].lower()\n",
    "    \n",
    "    if extract == \".pdf\":\n",
    "        return extract_text_from_pdf(file_path)\n",
    "    elif extract == \".docx\":\n",
    "        docs = Document(file_path)\n",
    "        return '\\n'.join([para.text for para in docs.paragraphs])\n",
    "    elif extract == \".txt\":\n",
    "        with open(file_path, 'r',encoding = 'utf-8', errors = 'ignore') as f:\n",
    "            return f.read()\n",
    "    elif extract in ['.png','.webp', '.jpg','.jpeg']:\n",
    "        return extract_text_from_image(file_path)\n",
    "    else:\n",
    "        raise ValueError(f\"unsupported file type : {extract}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfa444c8-1b4e-4ec6-b939-545a4068619e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text:\n",
      " A s h o k   L a m s a l\n",
      "Tech enthusiast, CS student at TU\n",
      "\n",
      "Khairahani-6, Chitwan ,  Parsa\n",
      "\n",
      "9865254615\n",
      "\n",
      "ashoklamsal007@gmail.com\n",
      "\n",
      " @ https://www.linkedin.com/in/ashok-lamsal-8576311b9/\n",
      "\n",
      "Passionate, dedicated sixth-semester BSC CSIT student with a passion for technology. I am actively delving into Python for machine\n",
      "learning and have solid foundation in C, C++, and data structures with  basic knowledge of web development. I am currently\n",
      "exploring \u0000elds of ML and data science using numpy pandas, matplotlib, seaborne and scikitlearn\n",
      "\n",
      "EX PER IENCE\n",
      "\n",
      "School Teacher\n",
      "\n",
      "Shree basic School Basyouli\n",
      "\n",
      "Work as lower secondary level Science and Math teacher. \n",
      "\n",
      "Project lead\n",
      "\n",
      "Code For Change\n",
      "\n",
      "Khairahani\n",
      "\n",
      "Jul, 2023 - Jul, 2024\n",
      "\n",
      "Chitwan\n",
      "\n",
      "Jan, 2025 - Present\n",
      "\n",
      "Lead the team of CFC Chitwan, a nonpro\u0000t, nonpolitical student community actively organizing events and workshops in the\n",
      "Chitwan region. \n",
      "\n",
      "Microsoft learnt student ambassador\n",
      "\n",
      "Microsoft\n",
      "\n",
      "Beta MLSA participated in multiple events and recently organized an Azure fundamentals workshop.\n",
      "\n",
      "ED UCAT IO N\n",
      "\n",
      "Bsc CSIT\n",
      "\n",
      "Birendra Multiple Campus\n",
      "\n",
      "SLC\n",
      "\n",
      "Daisy English Boarding Secondary School\n",
      "\n",
      "BIo-Science (11 and 12 )  GPA: 3.66\n",
      "\n",
      "SEE\n",
      "\n",
      "Shree Khairahani Secondary School\n",
      "\n",
      "PR O JECT S\n",
      "\n",
      "Loading......\n",
      "\n",
      "T R A INING /CER T IF ICAT IO NS\n",
      "\n",
      "7 days data science workshop\n",
      "\n",
      "Code for Change\n",
      "\n",
      "Microsoft o\u0000ce package training\n",
      "\n",
      "C SE Chitwan\n",
      "\n",
      "public speaking training\n",
      "\n",
      "Great FM\n",
      "\n",
      "7 days junior youth Redcross operation management training\n",
      "\n",
      "Nepal Red Cross Society, Bagmati Province\n",
      "\n",
      "Bharatpur\n",
      "\n",
      "Jul, 2024 - Present\n",
      "\n",
      "Bharatpur\n",
      "\n",
      "Mar, 2022 - Present\n",
      "\n",
      "khairahani\n",
      "\n",
      "Aug, 2019 - Sep, 2021\n",
      "\n",
      "Khairahani\n",
      "\n",
      "Apr, 2008 - Jun, 2019\n",
      "\n",
      "2024\n",
      "\n",
      "2022\n",
      "\n",
      "2020\n",
      "\n",
      "2019\n",
      "\n",
      "\f",
      "Associate data science program\n",
      "\n",
      "2024\n",
      "\n",
      "DataCamp\n",
      "\n",
      "S K ILLS\n",
      "\n",
      "programming language : C, C++, Data science software libraries: Python (NumPy, Pandas,Maplotlib,Seaborn, Scikit learn), Soft skill\n",
      ": Leadership, Problem-Solving, Communication, Teamwork and Collaboration ....\n",
      "\n",
      "LA NG UA G E\n",
      "\n",
      "Nepali, English, Hindi\n",
      "\n",
      "R EF ER ENCES\n",
      "\n",
      "Daya Ram Poudel - Campus Chief\n",
      "\n",
      "Shiva raj Adhikari - Principal\n",
      "\n",
      "Birendra Multiple Campus\n",
      "+977 9855019253\n",
      "\n",
      "Shree Basic School, Basyouli\n",
      "+977 9855062262\n",
      "adhikariji90@gmail.com\n",
      "\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Extract and Save Resume Text \n",
    "file_path = '../data/cv.pdf'  # Your file\n",
    "\n",
    "try:\n",
    "    # Extract text\n",
    "    extracted_text = extract_text(file_path)\n",
    "    print(\"Extracted Text:\\n\", extracted_text)\n",
    "\n",
    "    # Generate dynamic file name based on input file\n",
    "    base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    dynamic_txt_file = f\"{base_name}_extracted.txt\"\n",
    "\n",
    "    # Save to .txt file\n",
    "    with open(dynamic_txt_file, \"w\", encoding=\"utf-8\") as out_file:\n",
    "        out_file.write(extracted_text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56b0385f-4842-41eb-a565-ab92e08634f9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#to pass raw extracted text into nlp piplines which gives processed object doc\n",
    "doc = nlp(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3c3827e-3a27-4b9a-b807-600f5ac76ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 3: defining the parsing function \n",
    "import re\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "EDUCATION_KEYWORDS = [\n",
    "    \"bachelor\", \"master\", \"b.sc\", \"b.tech\", \"m.tech\", \"be\", \"bs\", \"ms\", \n",
    "    \"university\", \"school\", \"college\", \"diploma\", \"education\"\n",
    "]\n",
    "\n",
    "SKILL_KEYWORDS = [\n",
    "    \"python\", \"java\", \"sql\", \"c++\", \"tensorflow\", \"keras\", \"pytorch\", \"machine learning\",\n",
    "    \"deep learning\", \"nlp\", \"flask\", \"django\", \"pandas\", \"numpy\", \"matplotlib\", \"streamlit\",\n",
    "    \"data analysis\", \"communication\", \"fastapi\", \"transformers\", \"langchain\", \"docker\", \"aws\", \"azure\"\n",
    "]\n",
    "\n",
    "def extract_resume_details(text):\n",
    "    result = {\n",
    "        \"NAME\": None,\n",
    "        \"EMAIL\": None,\n",
    "        \"PHONE\": None,\n",
    "        \"LINKEDIN\": None,\n",
    "        \"GITHUB\": None,\n",
    "        \"SKILLS\": [],\n",
    "        \"EDUCATION\": [],\n",
    "        \"EXPERIENCE\": [],\n",
    "        \"PROJECTS\": []\n",
    "    }\n",
    "\n",
    "    # Clean up text\n",
    "    text = text.replace('\\r', '').replace('\\t', '').replace('|', ' ')\n",
    "    lines = [line.strip() for line in text.split('\\n') if line.strip()]\n",
    "    full_text = \" \".join(lines)\n",
    "\n",
    "    # 2.  Try to extract name from top 300 characters manually\n",
    "    lines = text[:300].split('\\n')\n",
    "    for line in lines:\n",
    "        joined = ''.join(line.split())  # Remove all internal spaces (e.g., \"A s h o k\")\n",
    "        words = re.findall(r'[A-Z][a-z]*', joined)  # Match proper words\n",
    "        if 2 <= len(words) <= 4:  # Likely a full name\n",
    "            result[\"NAME\"] = ' '.join(words)\n",
    "            break\n",
    "\n",
    "\n",
    "    # 2. Email\n",
    "    emails = re.findall(r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\", full_text)\n",
    "    result[\"EMAIL\"] = emails[0] if emails else None\n",
    "\n",
    "    # 3. Phone number (basic international + local pattern)\n",
    "    phones = re.findall(r\"\\+?\\d[\\d\\s\\-]{8,15}\\d\", full_text)\n",
    "    result[\"PHONE\"] = phones[0] if phones else None\n",
    "\n",
    "    # 4. LinkedIn\n",
    "    linkedin = re.findall(r\"https?://(?:www\\.)?linkedin\\.com/[a-zA-Z0-9/_\\-\\.]+\", full_text.lower())\n",
    "    result[\"LINKEDIN\"] = linkedin[0] if linkedin else None\n",
    "\n",
    "    # 5. GitHub\n",
    "    github = re.findall(r\"https?://(?:www\\.)?github\\.com/[a-zA-Z0-9/_\\-\\.]+\", full_text.lower())\n",
    "    result[\"GITHUB\"] = github[0] if github else None\n",
    "\n",
    "\n",
    "    # 6. Skills (keyword match)\n",
    "    found_skills = set()\n",
    "    for keyword in SKILL_KEYWORDS:\n",
    "        if re.search(r\"\\b\" + re.escape(keyword.lower()) + r\"\\b\", full_text.lower()):\n",
    "            found_skills.add(keyword.lower())\n",
    "    result[\"SKILLS\"] = sorted(list(found_skills))\n",
    "\n",
    "    # 7. Education\n",
    "    education = []\n",
    "    for line in lines:\n",
    "        if any(kw in line.lower() for kw in EDUCATION_KEYWORDS) or re.search(r\"\\b(20\\d{2}|19\\d{2})\\b\", line):\n",
    "            education.append(line)\n",
    "    result[\"EDUCATION\"] = education\n",
    "\n",
    "    # 8. Experience / Projects\n",
    "    experience = []\n",
    "    projects = []\n",
    "    in_experience = False\n",
    "    in_projects = False\n",
    "\n",
    "    for line in lines:\n",
    "        line_lower = line.lower()\n",
    "        if \"experience\" in line_lower:\n",
    "            in_experience = True\n",
    "            in_projects = False\n",
    "            continue\n",
    "        elif \"project\" in line_lower:\n",
    "            in_projects = True\n",
    "            in_experience = False\n",
    "            continue\n",
    "        elif \"education\" in line_lower:\n",
    "            in_projects = False\n",
    "            in_experience = False\n",
    "            continue\n",
    "\n",
    "        if in_experience:\n",
    "            experience.append(line)\n",
    "        elif in_projects:\n",
    "            projects.append(line)\n",
    "\n",
    "    result[\"EXPERIENCE\"] = list(dict.fromkeys(experience))\n",
    "    result[\"PROJECTS\"] = list(dict.fromkeys(projects))\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6828cb81-67ea-4d56-b339-dd876cc1cf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME: Ashok Lamsal\n",
      "EMAIL: ashoklamsal007@gmail.com\n",
      "PHONE: 9865254615\n",
      "LINKEDIN: https://www.linkedin.com/in/ashok-lamsal-8576311b9/\n",
      "GITHUB: None\n",
      "SKILLS: ['azure', 'communication', 'machine learning', 'matplotlib', 'numpy', 'pandas', 'python']\n",
      "EDUCATION: ['ashoklamsal007@gmail.com', '\\uf0e1 @ https://www.linkedin.com/in/ashok-lamsal-8576311b9/', 'Passionate, dedicated sixth-semester BSC CSIT student with a passion for technology. I am actively delving into Py']\n",
      "EXPERIENCE: []\n",
      "PROJECTS: []\n"
     ]
    }
   ],
   "source": [
    "#  Step 4: Load the same dynamic file for parsing \n",
    "with open(dynamic_txt_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    resume_text = f.read()\n",
    "\n",
    "details = extract_resume_details(resume_text)\n",
    "\n",
    "# Step 5: Print the extracted structured details \n",
    "for k, v in details.items():\n",
    "    print(f\"{k.upper()}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0597b3f8-c849-4e95-8c80-072a6558b4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resume text preprocessing\n",
    "import re\n",
    "\n",
    "def clean_resume_text(text):\n",
    "    # Remove extra whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # Fix broken headers like \"E X P E R I E N C E\"\n",
    "    headers = ['EXPERIENCE', 'PROJECTS', 'EDUCATION', 'SKILLS', 'CERTIFICATIONS', 'TRAINING', 'REFERENCES']\n",
    "    for h in headers:\n",
    "        broken = r'\\s*'.join(h)  # turns 'EXPERIENCE' → 'E\\s*X\\s*P...'\n",
    "        text = re.sub(broken, h, text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Standardize headers to uppercase\n",
    "    text = re.sub(\n",
    "        r'(?i)(Experience|Projects|Education|Skills|Certifications|Training|References)',\n",
    "        lambda m: m.group().upper(),\n",
    "        text\n",
    "    )\n",
    "    \n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6d081cdf-7f93-4e15-ac79-27c66f78b3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_section(text, section):\n",
    "    \"\"\"\n",
    "    Extracts the content of a section from resume text.\n",
    "    \"\"\"\n",
    "    pattern = rf\"{section}\\s*(.*?)(?=(EXPERIENCE|PROJECTS|EDUCATION|SKILLS|CERTIFICATIONS|TRAINING|REFERENCES|$))\"\n",
    "    match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "    return match.group(1).strip() if match else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c3214e6b-c112-42b4-b06d-fb0b4a0f42b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_basic_fields(text):\n",
    "    name = None\n",
    "\n",
    "    # Clean text\n",
    "    cleaned_text = text.replace('\\r', '').replace('\\t', '').replace('|', ' ')\n",
    "    lines = cleaned_text.split('\\n')[:10]\n",
    "\n",
    "    # === Enhanced Name Extraction Logic (from Version 1) ===\n",
    "    for line in lines:\n",
    "        # Fix OCR-broken names like \"A s h o k   L a m s a l\"\n",
    "        joined = ''.join(line.split())\n",
    "\n",
    "        # Step 1: Try to split on capital letters\n",
    "        words = re.findall(r'[A-Z][a-z]{1,}', joined)\n",
    "        if 2 <= len(words) <= 4:\n",
    "            name = ' '.join(words)\n",
    "            break\n",
    "\n",
    "        # Step 2: Try normal full name pattern\n",
    "        match = re.match(r\"^[A-Z][a-z]+ [A-Z][a-z]+\", line.strip())\n",
    "        if match:\n",
    "            name = match.group().strip()\n",
    "            break\n",
    "\n",
    "    # === Other fields ===\n",
    "    email = re.findall(r\"[\\w\\.-]+@[\\w\\.-]+\", cleaned_text)\n",
    "    phone = re.findall(r\"\\+?\\d[\\d \\-\\(\\)]{8,14}\\d\", cleaned_text)\n",
    "    linkedin = re.findall(r\"(https?://[^\\s]*linkedin\\.com[^\\s]*)\", cleaned_text)\n",
    "    github = re.findall(r\"(https?://[^\\s]*github\\.com[^\\s]*)\", cleaned_text)\n",
    "\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"email\": email[0] if email else None,\n",
    "        \"phone\": phone[0] if phone else None,\n",
    "        \"linkedin\": linkedin[0] if linkedin else None,\n",
    "        \"github\": github[0] if github else None\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3ff4f82d-7807-4009-9db7-28a68a2814fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_resume(text):\n",
    "    text_clean = clean_resume_text(text)\n",
    "    cleaned_text = text.replace('\\r', '').replace('\\t', '').replace('|', ' ')\n",
    "\n",
    "    parsed = {\n",
    "        **extract_basic_fields(cleaned_text),\n",
    "        \"education\": extract_section(text_clean, \"EDUCATION\"),\n",
    "        \"experience\": extract_section(text_clean, \"EXPERIENCE\"),\n",
    "        \"projects\": extract_section(text_clean, \"PROJECTS\"),\n",
    "        \"skills\": extract_section(text_clean, \"SKILLS\"),\n",
    "        \"certifications\": extract_section(text_clean, \"CERTIFICATIONS\")\n",
    "    }\n",
    "\n",
    "    return parsed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "183d3089-816d-4b13-817c-3bdb4b37400f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Ashok Lamsal',\n",
       " 'email': 'ashoklamsal007@gmail.com',\n",
       " 'phone': '9865254615',\n",
       " 'linkedin': 'https://www.linkedin.com/in/ashok-lamsal-8576311b9/',\n",
       " 'github': None,\n",
       " 'education': 'Bsc CSIT Birendra Multiple Campus SLC Daisy English Boarding Secondary School BIo-Science (11 and 12 ) GPA: 3.66 SEE Shree Khairahani Secondary School',\n",
       " 'experience': 'School Teacher Shree basic School Basyouli Work as lower secondary level Science and Math teacher. Project lead Code For Change Khairahani Jul, 2023 - Jul, 2024 Chitwan Jan, 2025 - Present Lead the team of CFC Chitwan, a nonpro\\x00t, nonpolitical student community actively organizing events and workshops in the Chitwan region. Microsoft learnt student ambassador Microsoft Beta MLSA participated in multiple events and recently organized an Azure fundamentals workshop.',\n",
       " 'projects': 'Loading......',\n",
       " 'skills': 'programming language : C, C++, Data science software libraries: Python (NumPy, Pandas,Maplotlib,Seaborn, Scikit learn), Soft skill : Leadership, Problem-Solving, Communication, Teamwork and Collaboration .... LA NG UA G E Nepali, English, Hindi',\n",
       " 'certifications': '7 days data science workshop Code for Change Microsoft o\\x00ce package'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(dynamic_txt_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    resume_text = f.read()\n",
    "\n",
    "parsed_resume = parse_resume(resume_text)\n",
    "parsed_resume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "185777a9-5c13-4f81-974d-347b946be36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>phone</th>\n",
       "      <th>linkedin</th>\n",
       "      <th>github</th>\n",
       "      <th>education</th>\n",
       "      <th>experience</th>\n",
       "      <th>projects</th>\n",
       "      <th>skills</th>\n",
       "      <th>certifications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ashok Lamsal</td>\n",
       "      <td>ashoklamsal007@gmail.com</td>\n",
       "      <td>9865254615</td>\n",
       "      <td>https://www.linkedin.com/in/ashok-lamsal-85763...</td>\n",
       "      <td>None</td>\n",
       "      <td>Bsc CSIT Birendra Multiple Campus SLC Daisy En...</td>\n",
       "      <td>School Teacher Shree basic School Basyouli Wor...</td>\n",
       "      <td>Loading......</td>\n",
       "      <td>programming language : C, C++, Data science so...</td>\n",
       "      <td>7 days data science workshop Code for Change M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name                     email       phone  \\\n",
       "0  Ashok Lamsal  ashoklamsal007@gmail.com  9865254615   \n",
       "\n",
       "                                            linkedin github  \\\n",
       "0  https://www.linkedin.com/in/ashok-lamsal-85763...   None   \n",
       "\n",
       "                                           education  \\\n",
       "0  Bsc CSIT Birendra Multiple Campus SLC Daisy En...   \n",
       "\n",
       "                                          experience       projects  \\\n",
       "0  School Teacher Shree basic School Basyouli Wor...  Loading......   \n",
       "\n",
       "                                              skills  \\\n",
       "0  programming language : C, C++, Data science so...   \n",
       "\n",
       "                                      certifications  \n",
       "0  7 days data science workshop Code for Change M...  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([parsed_resume])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4aaacd-6337-4952-aaae-ee0b7672f5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
