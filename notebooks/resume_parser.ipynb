{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5799070-f439-4a2f-804e-12f028731414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8285e844-cf35-4571-a0de-79070c542261",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.7\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5923ee6e-807b-4ba5-af20-32485f29d25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize and load pretrained model from SpaCy which include tokenizer, tagger, parser,  NER, lemmatizer\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28be8142-3ba5-44ea-b89d-edf8dd167c40",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pytesseract) (24.1)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pytesseract) (10.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c29393b-a5f1-41ac-bfeb-9e40802f813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1: functional block for extracting the resume texts \n",
    "\n",
    "from pdfminer.high_level import extract_text as extract_text_from_pdf\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import docx\n",
    "from docx import Document\n",
    "import os\n",
    "import re\n",
    "\n",
    "def extract_text_from_image(file_path):\n",
    "    img = Image.open(file_path)\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    return text\n",
    "\n",
    "def extract_text(file_path):\n",
    "    extract = os.path.splitext(file_path)[-1].lower()\n",
    "    \n",
    "    if extract == \".pdf\":\n",
    "        return extract_text_from_pdf(file_path)\n",
    "    elif extract == \".docx\":\n",
    "        docs = Document(file_path)\n",
    "        return '\\n'.join([para.text for para in docs.paragraphs])\n",
    "    elif extract == \".txt\":\n",
    "        with open(file_path, 'r',encoding = 'utf-8', errors = 'ignore') as f:\n",
    "            return f.read()\n",
    "    elif extract in ['.png','.webp', '.jpg','.jpeg']:\n",
    "        return extract_text_from_image(file_path)\n",
    "    else:\n",
    "        raise ValueError(f\"unsupported file type : {extract}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56b0385f-4842-41eb-a565-ab92e08634f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to pass raw extracted text into nlp piplines which gives processed object doc\n",
    "doc = nlp(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9281781c-7ab8-4091-a536-1ca77642091d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text:\n",
      " A s h o k   L a m s a l\n",
      "Tech enthusiast, CS student at TU\n",
      "\n",
      "Khairahani-6, Chitwan ,¬† Parsa\n",
      "\n",
      "9865254615\n",
      "\n",
      "ashoklamsal007@gmail.com\n",
      "\n",
      "ÔÉ° @ https://www.linkedin.com/in/ashok-lamsal-8576311b9/\n",
      "\n",
      "Passionate, dedicated sixth-semester BSC CSIT student with a passion for technology. I am actively delving into Python for machine\n",
      "learning and have solid foundation in C, C++, and data structures with¬† basic knowledge of web development. I am currently\n",
      "exploring \u0000elds of ML and data science using numpy pandas, matplotlib, seaborne and scikitlearn\n",
      "\n",
      "EX PER IENCE\n",
      "\n",
      "School Teacher\n",
      "\n",
      "Shree basic School Basyouli\n",
      "\n",
      "Work as lower secondary level Science and Math teacher.¬†\n",
      "\n",
      "Project lead\n",
      "\n",
      "Code For Change\n",
      "\n",
      "Khairahani\n",
      "\n",
      "Jul, 2023 - Jul, 2024\n",
      "\n",
      "Chitwan\n",
      "\n",
      "Jan, 2025 - Present\n",
      "\n",
      "Lead the team of CFC Chitwan, a nonpro\u0000t, nonpolitical student community actively organizing events and workshops in the\n",
      "Chitwan region.¬†\n",
      "\n",
      "Microsoft learnt student ambassador\n",
      "\n",
      "Microsoft\n",
      "\n",
      "Beta MLSA participated in multiple events and recently organized an Azure fundamentals workshop.\n",
      "\n",
      "ED UCAT IO N\n",
      "\n",
      "Bsc CSIT\n",
      "\n",
      "Birendra Multiple Campus\n",
      "\n",
      "SLC\n",
      "\n",
      "Daisy English Boarding Secondary School\n",
      "\n",
      "BIo-Science (11 and 12 )¬† GPA: 3.66\n",
      "\n",
      "SEE\n",
      "\n",
      "Shree Khairahani Secondary School\n",
      "\n",
      "PR O JECT S\n",
      "\n",
      "Loading......\n",
      "\n",
      "T R A INING /CER T IF ICAT IO NS\n",
      "\n",
      "7 days data science workshop\n",
      "\n",
      "Code for Change\n",
      "\n",
      "Microsoft o\u0000ce package training\n",
      "\n",
      "C SE Chitwan\n",
      "\n",
      "public speaking training\n",
      "\n",
      "Great FM\n",
      "\n",
      "7 days junior youth Redcross operation management training\n",
      "\n",
      "Nepal Red Cross Society, Bagmati Province\n",
      "\n",
      "Bharatpur\n",
      "\n",
      "Jul, 2024 - Present\n",
      "\n",
      "Bharatpur\n",
      "\n",
      "Mar, 2022 - Present\n",
      "\n",
      "khairahani\n",
      "\n",
      "Aug, 2019 - Sep, 2021\n",
      "\n",
      "Khairahani\n",
      "\n",
      "Apr, 2008 - Jun, 2019\n",
      "\n",
      "2024\n",
      "\n",
      "2022\n",
      "\n",
      "2020\n",
      "\n",
      "2019\n",
      "\n",
      "\f",
      "Associate data science program\n",
      "\n",
      "2024\n",
      "\n",
      "DataCamp\n",
      "\n",
      "S K ILLS\n",
      "\n",
      "programming language : C, C++, Data science software libraries: Python (NumPy, Pandas,Maplotlib,Seaborn, Scikit learn), Soft skill\n",
      ": Leadership, Problem-Solving, Communication, Teamwork and Collaboration ....\n",
      "\n",
      "LA NG UA G E\n",
      "\n",
      "Nepali, English, Hindi\n",
      "\n",
      "R EF ER ENCES\n",
      "\n",
      "Daya Ram Poudel - Campus Chief\n",
      "\n",
      "Shiva raj Adhikari - Principal\n",
      "\n",
      "Birendra Multiple Campus\n",
      "+977 9855019253\n",
      "\n",
      "Shree Basic School, Basyouli\n",
      "+977 9855062262\n",
      "adhikariji90@gmail.com\n",
      "\n",
      "\f",
      "\n",
      "‚úÖ Text saved to: ../data/extracted_text_sample\\cv_extracted_20250519_094249.txt\n",
      "üìù Log updated at: ../data/extracted_text_sample\\log.txt\n"
     ]
    }
   ],
   "source": [
    "#step 2: to save and update extracted text file with log details\n",
    "from datetime import datetime\n",
    "from pdfminer.high_level import extract_text  # Make sure it's imported\n",
    "\n",
    "# Step 1: Define the input file path\n",
    "file_path = '../data/cv.pdf'  # Your input file\n",
    "\n",
    "try:\n",
    "    # Step 2: Extract text\n",
    "    extracted_text = extract_text(file_path)\n",
    "    print(\"Extracted Text:\\n\", extracted_text)\n",
    "\n",
    "    # Step 3: Prepare output directory\n",
    "    output_dir = \"../data/extracted_text_sample\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Step 4: Generate output filename based on input file\n",
    "    base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_filename = f\"{base_name}_extracted_{timestamp}.txt\"\n",
    "    dynamic_txt_file = os.path.join(output_dir, output_filename)\n",
    "\n",
    "    # Step 5: Save extracted text to file\n",
    "    with open(dynamic_txt_file, \"w\", encoding=\"utf-8\") as out_file:\n",
    "        out_file.write(extracted_text)\n",
    "\n",
    "    # Step 6: Log saved file\n",
    "    log_file_path = os.path.join(output_dir, \"log.txt\")\n",
    "    with open(log_file_path, \"a\", encoding=\"utf-8\") as log_file:\n",
    "        log_file.write(f\"{datetime.now()} - Saved: {output_filename}\\n\")\n",
    "\n",
    "    print(f\"‚úÖ Text saved to: {dynamic_txt_file}\")\n",
    "    print(f\"üìù Log updated at: {log_file_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0597b3f8-c849-4e95-8c80-072a6558b4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resume text preprocessing to get clear extracted text only\n",
    "\n",
    "def clean_resume_text(text):\n",
    "    # Remove extra whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # Fix broken headers like \"E X P E R I E N C E\"\n",
    "    headers = ['EXPERIENCE', 'PROJECTS', 'EDUCATION', 'SKILLS', 'CERTIFICATIONS', 'TRAINING', 'REFERENCES']\n",
    "    for h in headers:\n",
    "        broken = r'\\s*'.join(h)  # turns 'EXPERIENCE' ‚Üí 'E\\s*X\\s*P...'\n",
    "        text = re.sub(broken, h, text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Standardize headers to uppercase\n",
    "    text = re.sub(\n",
    "        r'(?i)(Experience|Projects|Education|Skills|Certifications|Training|References)',\n",
    "        lambda m: m.group().upper(),\n",
    "        text\n",
    "    )\n",
    "    \n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d081cdf-7f93-4e15-ac79-27c66f78b3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_section(text, section):\n",
    "    \"\"\"\n",
    "    Extracts the content of a section from resume text.\n",
    "    \"\"\"\n",
    "    pattern = rf\"{section}\\s*(.*?)(?=(EXPERIENCE|PROJECTS|EDUCATION|SKILLS|CERTIFICATIONS|TRAINING|REFERENCES|$))\"\n",
    "    match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "    return match.group(1).strip() if match else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3214e6b-c112-42b4-b06d-fb0b4a0f42b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_basic_fields(text):\n",
    "    name = None\n",
    "\n",
    "    # Clean text\n",
    "    cleaned_text = text.replace('\\r', '').replace('\\t', '').replace('|', ' ')\n",
    "    lines = cleaned_text.split('\\n')[:10]\n",
    "\n",
    "    #  Enhanced Name Extraction Logic (from Version 1) =\n",
    "    for line in lines:\n",
    "        # Fix OCR-broken names \n",
    "        joined = ''.join(line.split())\n",
    "\n",
    "        # Step 1: Try to split on capital letters\n",
    "        words = re.findall(r'[A-Z][a-z]{1,}', joined)\n",
    "        if 2 <= len(words) <= 4:\n",
    "            name = ' '.join(words)\n",
    "            break\n",
    "\n",
    "        # Step 2: Try normal full name pattern\n",
    "        match = re.match(r\"^[A-Z][a-z]+ [A-Z][a-z]+\", line.strip())\n",
    "        if match:\n",
    "            name = match.group().strip()\n",
    "            break\n",
    "\n",
    "    #  Other basic details fields \n",
    "    email = re.findall(r\"[\\w\\.-]+@[\\w\\.-]+\", cleaned_text)\n",
    "    phone = re.findall(r\"\\+?\\d[\\d \\-\\(\\)]{8,14}\\d\", cleaned_text)\n",
    "    linkedin = re.findall(r\"(https?://[^\\s]*linkedin\\.com[^\\s]*)\", cleaned_text)\n",
    "    github = re.findall(r\"(https?://[^\\s]*github\\.com[^\\s]*)\", cleaned_text)\n",
    "\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"email\": email[0] if email else None,\n",
    "        \"phone\": phone[0] if phone else None,\n",
    "        \"linkedin\": linkedin[0] if linkedin else None,\n",
    "        \"github\": github[0] if github else None\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ff4f82d-7807-4009-9db7-28a68a2814fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main parsing function\n",
    "def parse_resume(text):\n",
    "    text_clean = clean_resume_text(text)\n",
    "    cleaned_text = text.replace('\\r', '').replace('\\t', '').replace('|', ' ')\n",
    "\n",
    "    parsed = {\n",
    "        **extract_basic_fields(cleaned_text),\n",
    "        \"education\": extract_section(text_clean, \"EDUCATION\"),\n",
    "        \"experience\": extract_section(text_clean, \"EXPERIENCE\"),\n",
    "        \"projects\": extract_section(text_clean, \"PROJECTS\"),\n",
    "        \"skills\": extract_section(text_clean, \"SKILLS\"),\n",
    "        \"certifications\": extract_section(text_clean, \"CERTIFICATIONS\")\n",
    "    }\n",
    "\n",
    "    return parsed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "183d3089-816d-4b13-817c-3bdb4b37400f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Ashok Lamsal',\n",
       " 'email': 'ashoklamsal007@gmail.com',\n",
       " 'phone': '9865254615',\n",
       " 'linkedin': 'https://www.linkedin.com/in/ashok-lamsal-8576311b9/',\n",
       " 'github': None,\n",
       " 'education': 'Bsc CSIT Birendra Multiple Campus SLC Daisy English Boarding Secondary School BIo-Science (11 and 12 ) GPA: 3.66 SEE Shree Khairahani Secondary School',\n",
       " 'experience': 'School Teacher Shree basic School Basyouli Work as lower secondary level Science and Math teacher. Project lead Code For Change Khairahani Jul, 2023 - Jul, 2024 Chitwan Jan, 2025 - Present Lead the team of CFC Chitwan, a nonpro\\x00t, nonpolitical student community actively organizing events and workshops in the Chitwan region. Microsoft learnt student ambassador Microsoft Beta MLSA participated in multiple events and recently organized an Azure fundamentals workshop.',\n",
       " 'projects': 'Loading......',\n",
       " 'skills': 'programming language : C, C++, Data science software libraries: Python (NumPy, Pandas,Maplotlib,Seaborn, Scikit learn), Soft skill : Leadership, Problem-Solving, Communication, Teamwork and Collaboration .... LA NG UA G E Nepali, English, Hindi',\n",
       " 'certifications': '7 days data science workshop Code for Change Microsoft o\\x00ce package'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking structured output for above parsed text \n",
    "with open(dynamic_txt_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    resume_text = f.read()\n",
    "\n",
    "parsed_resume = parse_resume(resume_text)\n",
    "parsed_resume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "185777a9-5c13-4f81-974d-347b946be36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>phone</th>\n",
       "      <th>linkedin</th>\n",
       "      <th>github</th>\n",
       "      <th>education</th>\n",
       "      <th>experience</th>\n",
       "      <th>projects</th>\n",
       "      <th>skills</th>\n",
       "      <th>certifications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ashok Lamsal</td>\n",
       "      <td>ashoklamsal007@gmail.com</td>\n",
       "      <td>9865254615</td>\n",
       "      <td>https://www.linkedin.com/in/ashok-lamsal-85763...</td>\n",
       "      <td>None</td>\n",
       "      <td>Bsc CSIT Birendra Multiple Campus SLC Daisy En...</td>\n",
       "      <td>School Teacher Shree basic School Basyouli Wor...</td>\n",
       "      <td>Loading......</td>\n",
       "      <td>programming language : C, C++, Data science so...</td>\n",
       "      <td>7 days data science workshop Code for Change M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name                     email       phone  \\\n",
       "0  Ashok Lamsal  ashoklamsal007@gmail.com  9865254615   \n",
       "\n",
       "                                            linkedin github  \\\n",
       "0  https://www.linkedin.com/in/ashok-lamsal-85763...   None   \n",
       "\n",
       "                                           education  \\\n",
       "0  Bsc CSIT Birendra Multiple Campus SLC Daisy En...   \n",
       "\n",
       "                                          experience       projects  \\\n",
       "0  School Teacher Shree basic School Basyouli Wor...  Loading......   \n",
       "\n",
       "                                              skills  \\\n",
       "0  programming language : C, C++, Data science so...   \n",
       "\n",
       "                                      certifications  \n",
       "0  7 days data science workshop Code for Change M...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([parsed_resume])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4aaacd-6337-4952-aaae-ee0b7672f5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Career venv)",
   "language": "python",
   "name": "career_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
